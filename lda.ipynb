{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xlsxFP4 = pd.ExcelFile(\"dataset/cordisfp4projects.xlsx\")\n",
    "xlsxFP5 = pd.ExcelFile(\"dataset/cordis-fp5projects.xlsx\")\n",
    "xlsxFP6 = pd.ExcelFile(\"dataset/cordis-fp6projects.xlsx\")\n",
    "xlsxFP7 = pd.ExcelFile(\"dataset/cordis-fp7projects.xlsx\")\n",
    "xlsxH2020 = pd.ExcelFile(\"dataset/cordis-h2020projects.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataFP4 = xlsxFP4.parse()\n",
    "dataFP5 = xlsxFP5.parse()\n",
    "dataFP6 = xlsxFP6.parse()\n",
    "dataFP7 = xlsxFP7.parse()\n",
    "dataH2020 = xlsxH2020.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/core/generic.py:3547: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "df4 = dataFP4[['rcn', 'title', 'objective', 'subjects', 'frameworkProgramme']]\n",
    "df4.frameworkProgramme.replace(to_replace=df4['frameworkProgramme'].astype(str),value='FP4', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "df5 = dataFP5[['rcn', 'title', 'objective', 'subjects', 'frameworkProgramme']]\n",
    "df5.frameworkProgramme.replace(to_replace=df5['frameworkProgramme'].astype(str),value='FP5', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df6 = dataFP6[['rcn', 'title', 'objective', 'subjects', 'frameworkProgramme']]\n",
    "df6.frameworkProgramme.replace(to_replace=np.NaN,value='FP6', inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df7 = dataFP7[['rcn', 'title', 'objective', 'subjects', 'frameworkProgramme']]\n",
    "df7.frameworkProgramme.replace(to_replace=np.NaN, value='FP7', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df20 = dataH2020[['rcn', 'title', 'objective', 'subjects', 'frameworkProgramme']]\n",
    "df20.frameworkProgramme.replace(to_replace=np.NaN, value='H2020', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the 'objective' of all the projects into a list\n",
    "list_obj = df4['objective'].tolist()\n",
    "list5 = df5['objective'].tolist()\n",
    "list6 = df6['objective'].tolist()\n",
    "list7 = df7['objective'].tolist()\n",
    "list20 = df20['objective'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_obj.extend(list5)\n",
    "list_obj.extend(list6)\n",
    "list_obj.extend(list7)\n",
    "list_obj.extend(list20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import string\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove common words\n",
    "en_stop.extend(['will', 'develop', 'project', 'research', 'new', 'use', 'european'])\n",
    "\n",
    "texts_1 = []\n",
    "\n",
    "for text in list_obj:\n",
    "    \n",
    "    try:\n",
    "        # 'text' is a float type\n",
    "        text = str(text)\n",
    "    except UnicodeEncodeError:\n",
    "        pass\n",
    "        \n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation & numbers\n",
    "    exclude_punctuation = list(string.punctuation)\n",
    "    numbers = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '0']\n",
    "    exclude_punctuation.extend(numbers)\n",
    "    \n",
    "    if text != 'nan':\n",
    "        text = text.replace('%l', '')\n",
    "        for c in exclude_punctuation:\n",
    "            text = text.replace(c, \" \")\n",
    "        \n",
    "        # tokenize document string\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        \n",
    "        # remove stop words from tokens\n",
    "        stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "        \n",
    "        stopped_tokens = [i for i in stopped_tokens if not i in ['develop', 'understand', 'model', 'eu', 'europe']]\n",
    "        \n",
    "        # stem tokens\n",
    "        stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "        \n",
    "        # add tokens to list\n",
    "        texts_1.append(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn our tokenized documents into a id <-> term dictionary\n",
    "dictionary = corpora.Dictionary(texts_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert tokenized documents into a document-term matrix\n",
    "corpus = [dictionary.doc2bow(text) for text in texts_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, u'0.014*product + 0.012*energi + 0.012*market + 0.009*technolog + 0.008*develop'), (1, u'0.009*innov + 0.007*research + 0.007*develop + 0.006*train + 0.006*activ'), (2, u'0.010*studi + 0.006*theori + 0.006*chang + 0.006*propos + 0.006*model'), (3, u'0.014*system + 0.009*technolog + 0.008*develop + 0.008*applic + 0.007*base'), (4, u'0.015*cell + 0.007*function + 0.006*diseas + 0.006*studi + 0.006*use')]\n"
     ]
    }
   ],
   "source": [
    "# generate LDA model\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=5, id2word = dictionary)\n",
    "\n",
    "print(ldamodel.print_topics(num_topics=5, num_words=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
