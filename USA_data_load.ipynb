{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Projects funded from USA (NSF)</h3>\n",
    "\n",
    "<p>The National Science Foundation (NSF) funds research and education in science and engineering, through grants, contracts, and cooperative agreements. The Foundation accounts for about 20 percent of federal support to academic institutions for basic research. \n",
    "\n",
    "Information about research projects that NSF has funded since 1989 can be found by searching the Award Abstracts database (https://www.nsf.gov/awardsearch/download.jsp). The information includes abstracts that describe the research, and names of principal investigators and their institutions. The database includes both completed and in-process research.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We will use all the provided information from 1994 till 2017 (259106 awards). The dataset consists of .zip folders for each year, with .xml files for each award.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import cjson\n",
    "import pandas as pd\n",
    "import xmltodict, json\n",
    "\n",
    "from xml.dom.minidom import parse\n",
    "\n",
    "filenames = os.listdir('USA_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>First, we unzip each folder and then for each file of the folder, we convert the xml file to a dictionary with:\n",
    "<ul>\n",
    "<li>key: the file name/award id (ex. 9601223)</li>\n",
    "<li>value: the actual content of the xml file in JSON format</li>\n",
    "</ul></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_text = {}\n",
    "\n",
    "for zipfilename in filenames:\n",
    "    with zipfile.ZipFile('USA_data/'+zipfilename) as z:\n",
    "        for filename in z.namelist():\n",
    "            if not os.path.isdir(filename):\n",
    "                try:\n",
    "                    with z.open(filename) as f:\n",
    "                        raw_text[filename[:-4]] = json.dumps(xmltodict.parse(f))\n",
    "                except:\n",
    "                    print filename\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>For each award/key of our dictionary, we create a new dictionary to keep the values that we'll use later on the analysis:\n",
    "<ul>\n",
    "<li>id: the award id</li>\n",
    "<li>title: the award title</li>\n",
    "<li>objective: the abstract narration of the award</li>\n",
    "<li>state: the code of the state</li>\n",
    "<li>subjects: information provided from 'Program Reference' and 'Program Element' values</li>\n",
    "<li>foa: FoaInformation</li>\n",
    "</ul>\n",
    "<br>\n",
    "Then, we append each dictionary to a list.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usa_list = []\n",
    "\n",
    "for key, val in raw_text.items():\n",
    "    usa_dict = {}\n",
    "\n",
    "    value = cjson.decode(val)\n",
    "    new_val = value['rootTag']['Award']\n",
    "\n",
    "    usa_dict['id'] = new_val['AwardID']\n",
    "    usa_dict['title'] = new_val['AwardTitle']\n",
    "    usa_dict['objective'] = new_val['AbstractNarration']\n",
    "    usa_dict['state'] = new_val['Institution']['StateCode']\n",
    "    \n",
    "    try:\n",
    "        if type(new_val['ProgramReference']) is dict:\n",
    "            usa_dict['subjects'] = new_val['ProgramElement']['Text'] + new_val['ProgramReference']['Text']\n",
    "        elif type(new_val['ProgramReference']) is list:\n",
    "            text = ''\n",
    "            for i in new_val['ProgramReference']:\n",
    "                text = text + ' ' + i['Text']\n",
    "\n",
    "            usa_dict['subjects'] = text\n",
    "        else:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "        if type(new_val['FoaInformation']) is dict:\n",
    "            usa_dict['foa'] = new_val['FoaInformation']['Name']\n",
    "        elif type(new_val['FoaInformation']) is list:\n",
    "            text = ''\n",
    "            for i in new_val['FoaInformation']:\n",
    "                text = text + ' ' + i['Name']\n",
    "\n",
    "            usa_dict['foa'] = text\n",
    "        else:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    usa_list.append(usa_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Finally, we use this list to create a Dataframe:<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f2c4de31b55f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdfUSA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musa_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdfUSA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfUSA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdfUSA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \"\"\"\n\u001b[1;32m   1212\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_clipboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexcel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/io/pickle.pyc\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(obj, path)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \"\"\"\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "dfUSA = pd.DataFrame(usa_list)\n",
    "dfUSA.to_pickle('dfUSA')\n",
    "dfUSA.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
