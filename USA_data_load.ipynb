{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Projects funded from USA (NSF)</h3>\n",
    "\n",
    "<p>The National Science Foundation (NSF) funds research and education in science and engineering, through grants, contracts, and cooperative agreements. The Foundation accounts for about 20 percent of federal support to academic institutions for basic research. \n",
    "\n",
    "Information about research projects that NSF has funded since 1989 can be found by searching the Award Abstracts database (https://www.nsf.gov/awardsearch/download.jsp). The information includes abstracts that describe the research, and names of principal investigators and their institutions. The database includes both completed and in-process research.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We will use all the provided information from 1994 till 2017 (259106 awards). The dataset consists of .zip folders for each year, with .xml files for each award.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import cjson\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xmltodict, json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>First, we unzip each folder and then for each file of the folder, we convert the xml file to a dictionary with:\n",
    "<ul>\n",
    "<li>key: the file name/award id (ex. 9601223)</li>\n",
    "<li>value: the actual content of the xml file in JSON format</li>\n",
    "</ul></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xml.dom.minidom import parse\n",
    "\n",
    "filenames = os.listdir('USA_data')\n",
    "\n",
    "raw_text = {}\n",
    "\n",
    "for zipfilename in filenames:\n",
    "    with zipfile.ZipFile('USA_data/'+zipfilename) as z:\n",
    "        for filename in z.namelist():\n",
    "            if not os.path.isdir(filename):\n",
    "                try:\n",
    "                    with z.open(filename) as f:\n",
    "                        raw_text[filename[:-4]] = json.dumps(xmltodict.parse(f))\n",
    "                except:\n",
    "                    print filename\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>For each award/key of our dictionary, we create a new dictionary to keep the values that we'll use later on the analysis:\n",
    "<ul>\n",
    "<li>id: the award id</li>\n",
    "<li>title: the award title</li>\n",
    "<li>objective: the abstract narration of the award</li>\n",
    "<li>state: the code of the state</li>\n",
    "<li>subjects: information provided from 'Program Reference' and 'Program Element' values</li>\n",
    "<li>foa: FoaInformation</li>\n",
    "</ul>\n",
    "<br>\n",
    "Then, we append each dictionary to a list.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usa_list = []\n",
    "\n",
    "for key, val in raw_text.items():\n",
    "    usa_dict = {}\n",
    "\n",
    "    value = cjson.decode(val)\n",
    "    new_val = value['rootTag']['Award']\n",
    "\n",
    "    usa_dict['id'] = new_val['AwardID']\n",
    "    usa_dict['title'] = new_val['AwardTitle']\n",
    "    usa_dict['objective'] = new_val['AbstractNarration']\n",
    "    usa_dict['state'] = new_val['Institution']['StateCode']\n",
    "    \n",
    "    if key[:2] in ['94', '95', '96', '97']:\n",
    "        usa_dict['framework_programme'] = 'FP4'\n",
    "    elif key[:2] in ['98', '99', '00', '01']:\n",
    "        usa_dict['framework_programme'] = 'FP5'\n",
    "    elif key[:2] in ['02', '03', '04', '05', '06']:\n",
    "        usa_dict['framework_programme'] = 'FP6'\n",
    "    elif key[:2] in ['07', '08', '09', '10', '11', '12', '13']:\n",
    "        usa_dict['framework_programme'] = 'FP7'\n",
    "    else:\n",
    "        usa_dict['framework_programme'] = 'H2020'\n",
    "    \n",
    "    try:\n",
    "        if type(new_val['ProgramReference']) is dict:\n",
    "            usa_dict['subjects'] = new_val['ProgramElement']['Text'] + new_val['ProgramReference']['Text']\n",
    "        elif type(new_val['ProgramReference']) is list:\n",
    "            text = ''\n",
    "            for i in new_val['ProgramReference']:\n",
    "                text = text + ' ' + i['Text']\n",
    "\n",
    "            usa_dict['subjects'] = text\n",
    "        else:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "        if type(new_val['FoaInformation']) is dict:\n",
    "            usa_dict['foa'] = new_val['FoaInformation']['Name']\n",
    "        elif type(new_val['FoaInformation']) is list:\n",
    "            text = ''\n",
    "            for i in new_val['FoaInformation']:\n",
    "                text = text + ' ' + i['Name']\n",
    "\n",
    "            usa_dict['foa'] = text\n",
    "        else:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    usa_list.append(usa_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Finally, we use this list to create a Dataframe:<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>foa</th>\n",
       "      <th>framework_programme</th>\n",
       "      <th>id</th>\n",
       "      <th>objective</th>\n",
       "      <th>state</th>\n",
       "      <th>subjects</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>FP7</td>\n",
       "      <td>1231468</td>\n",
       "      <td>Intellectual Merit: There is much to be learne...</td>\n",
       "      <td>NH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Using Next Generation Sequencing to Quantify t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>FP7</td>\n",
       "      <td>1039870</td>\n",
       "      <td>With this award from the Major Research Instru...</td>\n",
       "      <td>PA</td>\n",
       "      <td>MAJOR RESEARCH INSTRUMENTATION CHEMICAL INSTR...</td>\n",
       "      <td>MRI: Acquisition of a New 500 MHz NMR Console ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   foa framework_programme       id  \\\n",
       "0  NaN                 FP7  1231468   \n",
       "1  NaN                 FP7  1039870   \n",
       "\n",
       "                                           objective state  \\\n",
       "0  Intellectual Merit: There is much to be learne...    NH   \n",
       "1  With this award from the Major Research Instru...    PA   \n",
       "\n",
       "                                            subjects  \\\n",
       "0                                                NaN   \n",
       "1   MAJOR RESEARCH INSTRUMENTATION CHEMICAL INSTR...   \n",
       "\n",
       "                                               title  \n",
       "0  Using Next Generation Sequencing to Quantify t...  \n",
       "1  MRI: Acquisition of a New 500 MHz NMR Console ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfUSA = pd.DataFrame(usa_list)\n",
    "dfUSA.to_pickle('dfUSA')\n",
    "dfUSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfUSA = pd.read_pickle('dfUSA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259106,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objectives = dfUSA['objective']\n",
    "objectives.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    intellectual merit  there is much to be learne...\n",
       "1    with this award from the major research instru...\n",
       "Name: objective, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "RE_PUNCTUATION = '|'.join([re.escape(x) for x in string.punctuation])\n",
    "\n",
    "objectives = objectives.str.lower().str.replace('%l', '').str.replace(RE_PUNCTUATION, ' ')\n",
    "objectives.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [intellectual, merit, there, is, much, to, be,...\n",
       "1    [with, this, award, from, the, major, research...\n",
       "Name: objective, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objectives_split = objectives.str.split()\n",
    "objectives_split.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named gensim",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a1f21dadbbd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpora\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictionary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparsing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named gensim"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "from time import time\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "additional_stopwords = set(['computer', 'will', 'develop', 'development',\n",
    "                            'project', 'research', 'new', 'use', \n",
    "                            'europe', 'european'])\n",
    "stopwords = set(STOPWORDS) | additional_stopwords\n",
    "all_objectives_split = objectives_split.apply(lambda tokens: [token for token in tokens if token not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "objectives_dictionary = Dictionary(all_objectives_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ObjectivesCorpus(object):\n",
    "    def __init__(self, documents, dictionary):\n",
    "        self.documents = documents\n",
    "        self.dictionary = dictionary\n",
    "    def __iter__(self):\n",
    "        for document in self.documents:\n",
    "            yield self.dictionary.doc2bow(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "objectives_corpus = ObjectivesCorpus(all_objectives_split, objectives_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "lda = gensim.models.ldamulticore.LdaMulticore(corpus=objectives_corpus, \n",
    "                                              id2word=objectives_dictionary, \n",
    "                                              num_topics=10, \n",
    "                                              iterations=50,\n",
    "                                              passes=5)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
